{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Flatten,Embedding, TimeDistributed, Dense, GRU, Conv1D, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying input_shape\n",
    "\n",
    "input_shape, a tuple, always works\n",
    "\n",
    "Some 2D layers, such as dense, support input_dim and some 3D temporal layers support input_dim along with input_length.\n",
    "\n",
    "BUT input_shape always works\n",
    "\n",
    "### Input shapes by type\n",
    "\n",
    "**Dense:** input_shape=(number_of_features,)\n",
    "\n",
    "**Conv2D:** input_shape=(height,width,num_channels)\n",
    "\n",
    "**Embedding:** Embedding(vocab_size, output_dim=embed_size, input_length=max_seq_len)\n",
    "\n",
    "Time: \n",
    "- **RNN:** input_shape=(timesteps, number_of_features)\n",
    "- **Conv1D:** input_shape=(timesteps, number_of_features)\n",
    "- **timeDistributedDense**model.add(TimeDistributed(Dense(3),input_shape=(timesteps,features)))\n",
    "\n",
    "#### Uses\n",
    "* Embedding is generally the right input for dense-categorical input features (split them from the real numbers and concat later). It is also usually the right approach for 1D series of words (sequence classification or language models), though RNN and Conv1D can also be tried.\n",
    "* RNN, Conv1D, and TDD can all also be used for multivariable timeseries/longitudinal data. RNN and Conv1D run time-wise along each feature and concate the outputs of all. TDD acts as a timepoint embedding (applies the same dense transformation along the features at each timepoint). \n",
    "* Conv2D: images\n",
    "* Dense: real numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final layer and compile\n",
    "\n",
    "#### Binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=...)\n",
    "    On New data:\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "#### categorical classification\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=...)\n",
    "    On New data:\n",
    "    predicted = model.predict(X_test)\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "\n",
    "#### Regression\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse',...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY classification\n",
    "# 1000 examples, each w/100 features\n",
    "x_train = np.random.random((1000, 100))\n",
    "# either 0 or 1. 1k examples. shape is (1k,1), not (1k,)\n",
    "y_train = np.random.randint(2, size=(1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = np.random.randint(10, size=(1000,1))\n",
    "one_hot_labels = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "#\n",
    "x_test = np.random.random((100, 100))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequnces\n",
    "# NOTE, for sequence classification, you want the categorical example above\n",
    "# this produces an array of len(num_classes) for the labels\n",
    "number_of_features = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, number_of_features))\n",
    "y_train = np.random.random((1000, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN behavior\n",
    "\n",
    "n_units for an RNN is the 1D vector size you would like to use to represent each timestep the sequence that you are modeling.\n",
    "\n",
    "The representation for each timestep is determined by 'looking at' the current step and considering the previous steps. So, the representation of the final step can be thought of as the representation of the entire sequence.\n",
    "\n",
    "If you're going to pass the output to another recurrent layer, you want to return the representation of each timestep. If you're going to pass the output to a Dense layer (for classification etc) then you only want to return the final representation.\n",
    "\n",
    "**Exception**:If you wanted to classify EACH timestep in a sequence, instead of labeling the whole sequence you'd want to return all of the representations:\n",
    "    \n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    Will assign 1 of 3 labels to each timestep in you sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use return_sequences=T for every layer EXCEPT the last\n",
    "this is the representation of each timestep in the sequence\n",
    "    \n",
    "    model.add(LSTM(32, return_sequences=True))#returns a sequence of vectors of dimension 32\n",
    "\n",
    "use return_sequence=F to get only the output of the last timestept\n",
    "this is the representation of the entire sequence\n",
    "    \n",
    "    model.add(LSTM(32))  # return a single vector of dimension 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model play space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 591us/step - loss: 0.6991 - acc: 0.4975 - val_loss: 0.6998 - val_acc: 0.4650\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.6941 - acc: 0.5062 - val_loss: 0.6994 - val_acc: 0.4550\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.6934 - acc: 0.5087 - val_loss: 0.6995 - val_acc: 0.4550\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.6925 - acc: 0.5125 - val_loss: 0.6997 - val_acc: 0.4550\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.6923 - acc: 0.5225 - val_loss: 0.6998 - val_acc: 0.4450\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.6921 - acc: 0.5212 - val_loss: 0.6998 - val_acc: 0.4550\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.6918 - acc: 0.5262 - val_loss: 0.6997 - val_acc: 0.4600\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 92us/step - loss: 0.6918 - acc: 0.5325 - val_loss: 0.6998 - val_acc: 0.4650\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.6917 - acc: 0.5237 - val_loss: 0.6999 - val_acc: 0.4600\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 92us/step - loss: 0.6915 - acc: 0.5162 - val_loss: 0.6999 - val_acc: 0.4550\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "# BINARY classification\n",
    "# 1000 examples, each w/5 features\n",
    "x_train = np.random.random((1000, 5))\n",
    "# either 0 or 1. 1k examples. shape is (1k,1), not (1k,)\n",
    "y_train = np.random.randint(2, size=(1000,1))\n",
    "\n",
    "x_test = np.random.random((1000, 5))\n",
    "# either 0 or 1. 1k examples. shape is (1k,1), not (1k,)\n",
    "y_test = np.random.randint(2, size=(1000,1))\n",
    "\n",
    "\n",
    "# binary\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(5,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "#multi-class\n",
    "# history = model.fit(x_train, y=keras.utils.to_categorical(y_train), epochs=10, batch_size=32,\n",
    "#                    validation_split = 0.2)\n",
    "#binary\n",
    "history = model.fit(x_train, y=y_train, epochs=10,\n",
    "                   validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame({'epochs':history.epoch, 'train_loss': history.history['loss'], 'val_loss': history.history['val_loss']})\n",
    "g = sns.pointplot(x=\"epochs\", y=\"train_loss\", data=df, fit_reg=False)\n",
    "g = sns.pointplot(x=\"epochs\", y=\"val_loss\", data=df, fit_reg=False, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Predictions vs Groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_outcomes = pd.DataFrame({'class_prediction':model.predict_classes(x_test).flatten(),'class_probability': model.predict(x_test).flatten(),'true_outcome':y_test.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_po = pd.concat([pd.DataFrame(x_test),predictions_outcomes],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>class_prediction</th>\n",
       "      <th>class_probability</th>\n",
       "      <th>true_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139846</td>\n",
       "      <td>0.685071</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>0.972474</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.288612</td>\n",
       "      <td>0.190180</td>\n",
       "      <td>0.124092</td>\n",
       "      <td>0.376085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.489735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573151</td>\n",
       "      <td>0.615904</td>\n",
       "      <td>0.506474</td>\n",
       "      <td>0.114305</td>\n",
       "      <td>0.245147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.531386</td>\n",
       "      <td>0.881341</td>\n",
       "      <td>0.438206</td>\n",
       "      <td>0.166081</td>\n",
       "      <td>0.729551</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.306965</td>\n",
       "      <td>0.962802</td>\n",
       "      <td>0.201672</td>\n",
       "      <td>0.311183</td>\n",
       "      <td>0.239848</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4  class_prediction  \\\n",
       "0  0.139846  0.685071  0.781852  0.972474  0.217400                 0   \n",
       "1  0.422222  0.288612  0.190180  0.124092  0.376085                 0   \n",
       "2  0.573151  0.615904  0.506474  0.114305  0.245147                 0   \n",
       "3  0.531386  0.881341  0.438206  0.166081  0.729551                 0   \n",
       "4  0.306965  0.962802  0.201672  0.311183  0.239848                 0   \n",
       "\n",
       "   class_probability  true_outcome  \n",
       "0           0.462348             1  \n",
       "1           0.489735             0  \n",
       "2           0.468573             0  \n",
       "3           0.467051             0  \n",
       "4           0.457483             1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_po.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick and Dirty Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Assuming that you have a dataframe as input with 2 columns: \n",
    "- Text: the words in the sequence\n",
    "- Label: the classification for the sequence\n",
    "\n",
    "Steps:\n",
    "- Instantiate Tokenizer\n",
    "- fit_on_texts\n",
    "- texts_to_sequences\n",
    "- pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://shrikar.com/deep-learning-with-keras-and-python-for-multiclass-classification/\n",
    "import pandas as pd\n",
    "data = pd.read_csv('stackoverflow/stackoverflow.csv')\n",
    "data.rename(columns={'post':'Text','tags':'Label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get a distribution of the number of words in each text\n",
    "data['num_words'] = data.Text.apply(lambda x : len(x.split()))\n",
    "data.num_words.hist()\n",
    "\n",
    "# assign bins\n",
    "data['bins'] = pd.cut(data.num_words, bins=[0,300,600,np.inf],labels=['0-300','300-600','600-inf'])\n",
    "# word_distribution = data.groupby('bins').size().reset_index().rename(columns={0:'counts'})\n",
    "# word_distribution.head()\n",
    "data.bins.value_counts()\n",
    "\n",
    "MAXLEN = 600\n",
    "# convert tags to labels\n",
    "num_class = data.tags.nunique()\n",
    "data['targets'] = data.tags.astype('category').cat.codes\n",
    "labels_OH = to_categorical(data.targets,num_classes=num_class)\n",
    "\n",
    "# tokenizer object\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# fit tokenizer to text to create a dict\n",
    "tokenizer.fit_on_texts(data.post.values)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# assign new object using texts_to_sequences\n",
    "seqs = tokenizer.texts_to_sequences(data.post.values)\n",
    "# pad sequences\n",
    "padded_seqs = pad_sequences(seqs, maxlen=MAXLEN)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(padded_seqs,data.targets,stratify=data.targets,random_state=42,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "embedding_vecor_length= 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vecor_length, input_length=MAX_LENGTH))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(num_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/5\n",
      "5120/5120 [==============================] - 70s 14ms/step - loss: 1.0085 - acc: 0.5145 - val_loss: 0.5921 - val_acc: 0.7016\n",
      "Epoch 2/5\n",
      "5120/5120 [==============================] - 68s 13ms/step - loss: 0.3547 - acc: 0.8641 - val_loss: 0.3183 - val_acc: 0.9008\n",
      "Epoch 3/5\n",
      "5120/5120 [==============================] - 68s 13ms/step - loss: 0.1414 - acc: 0.9615 - val_loss: 0.2324 - val_acc: 0.9273\n",
      "Epoch 4/5\n",
      "5120/5120 [==============================] - 68s 13ms/step - loss: 0.0759 - acc: 0.9803 - val_loss: 0.2670 - val_acc: 0.9352\n",
      "Epoch 5/5\n",
      "5120/5120 [==============================] - 68s 13ms/step - loss: 0.0545 - acc: 0.9865 - val_loss: 0.3146 - val_acc: 0.9313\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,to_categorical(y_train,num_classes=num_class),validation_split=0.2,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict(x_test)\n",
    "probs = [i[np.argmax(i)] for i in probs]\n",
    "classes = model.predict_classes(x_test)\n",
    "c = data.Text.astype('category')\n",
    "d = dict(enumerate(c.cat.categories))\n",
    "d\n",
    "ff['category'] = ff['truth'].apply(lambda x: d[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Image Models\n",
    "\n",
    "This is fairly straight-forward, but code intensive. Checkout the following:\n",
    "\n",
    "- https://keras.io/applications/ : clear examples of transfer learning and fine-tuning\n",
    "- https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8 : More detailed examples including loading new data and image augmentation, etc. Also contains suggestions for each of the 4 primary scenarios when considering how new data relates to the pre-trained model\n",
    "- See HERE fastai notebooks for some nice image scrapping examples. \n",
    "\n",
    "In general, I greatly prefer the fastai framework for building/training image models, since these are typically clearly defined problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rec sys\n",
    "\n",
    "See notebook: rec_sys.ipynb for complete examples including visualizing the learned embedding space.\n",
    "\n",
    "For simple collaborative filtering, expect a dataframe w/3 columns: user_id, prod_id, rating where all are integers. \n",
    "\n",
    "1. Get num_users and num_products\n",
    "2. train,test split. Stratification doesn't make sense here so we skip it\n",
    "3. Input, Embed, Flatten for both legs: users,products\n",
    "4. prod = Dot(Axis=1, normalize=False) (or concate alternatively). Then add some dropout and dense layers following\n",
    "5. model = Model([productInput,userInput],prod)\n",
    "6. Compile/train\n",
    "7. Get predictions and maybe calc r2 in addition to mse\n",
    "8. Make recommendations: Feed in 1 user and ALL books: Then select the books that have the highest predicted rating for that specific user.\n",
    "\n",
    "Make recommendations\n",
    "\n",
    "    user_id = 1\n",
    "    user = np.array([user_id for i in range(len(book_list))])\n",
    "    predicted_ratings = model.predict([user,book_list]) \n",
    "    predicted_ratings = np.array([i[0] for i in predicted_ratings])\n",
    "    recommended_book_ids = (-predicted_ratings).argsort()\n",
    "    top_5 = recommended_book_ids[:5]\n",
    "    print(list(zip(top_5,predicted_ratings[top_5]))) # get the predicted rating for each rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all_data_dense.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>CDAI</th>\n",
       "      <th>CRP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>dmard</th>\n",
       "      <th>steroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>noDMARD</td>\n",
       "      <td>noSteroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>noDMARD</td>\n",
       "      <td>noSteroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>noDMARD</td>\n",
       "      <td>noSteroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>noDMARD</td>\n",
       "      <td>noSteroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>noDMARD</td>\n",
       "      <td>noSteroid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case  timepoint  CDAI  CRP       ESR    dmard    steroid\n",
       "0     0          0  0.00  0.0  0.000000  noDMARD  noSteroid\n",
       "1     0          1  0.00  0.0  0.000000  noDMARD  noSteroid\n",
       "2     0          2  0.00  0.0  0.000000  noDMARD  noSteroid\n",
       "3     0          3  0.08  0.0  0.100775  noDMARD  noSteroid\n",
       "4     1          0  0.00  0.0  0.000000  noDMARD  noSteroid"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dmard.nunique(), data.steroid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15+8+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('case',inplace=True)\n",
    "# assumes data is already sorted by case and timepoint\n",
    "del data['timepoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2312, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns=['dmard','steroid'])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578, 4, 26)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to timeseries format for modeling\n",
    "\n",
    "# assumes data is already sorted by case and timepoint\n",
    "# groupby creates a dictionary\n",
    "# here we use the case/person/stock_ticker etc as the key, which we will then ignore\n",
    "# we convert the value for each person into a list [person[time1_var1, time1_var2, time1_varN],[time2_var1,... ,time2_varN]]\n",
    "# and finally stack all patients into an array\n",
    "ts = np.stack([vv for kk,vv in data.groupby('case')])\n",
    "ts.shape\n",
    "\n",
    "# to see the above easily, just run this pipeline w/o the get_dummies cell above and compare\n",
    "# data.head() to ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, 'noDMARD', 'noSteroid'],\n",
       "       [0.0, 0.0, 0.0, 'noDMARD', 'noSteroid'],\n",
       "       [0.0, 0.0, 0.0, 'noDMARD', 'noSteroid'],\n",
       "       [0.08, 0.0, 0.100775193798, 'noDMARD', 'noSteroid']], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('all_set_label.csv')\n",
    "del labels['Unnamed: 0']\n",
    "# ingoring the group for now\n",
    "del labels['set']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps,features = ts.shape[1],ts.shape[2]\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(4,activation='relu'),input_shape=(timesteps,features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(32,recurrent_dropout = 0.3,activation='relu',\n",
    "              kernel_regularizer=l2(0.00674),\n",
    "              recurrent_regularizer=l2(0.00544)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation='relu',kernel_regularizer=l2(0.0005)))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 116 samples\n",
      "Epoch 1/50\n",
      "462/462 [==============================] - 4s 9ms/step - loss: 0.9244 - acc: 0.4286 - val_loss: 0.8918 - val_acc: 0.6207\n",
      "Epoch 2/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.8725 - acc: 0.5693 - val_loss: 0.8481 - val_acc: 0.6034\n",
      "Epoch 3/50\n",
      "462/462 [==============================] - 0s 379us/step - loss: 0.8323 - acc: 0.6039 - val_loss: 0.8131 - val_acc: 0.6034\n",
      "Epoch 4/50\n",
      "462/462 [==============================] - 0s 375us/step - loss: 0.7999 - acc: 0.6017 - val_loss: 0.7852 - val_acc: 0.6034\n",
      "Epoch 5/50\n",
      "462/462 [==============================] - 0s 376us/step - loss: 0.7749 - acc: 0.6017 - val_loss: 0.7618 - val_acc: 0.6034\n",
      "Epoch 6/50\n",
      "462/462 [==============================] - 0s 376us/step - loss: 0.7543 - acc: 0.6017 - val_loss: 0.7439 - val_acc: 0.6034\n",
      "Epoch 7/50\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.7375 - acc: 0.6017 - val_loss: 0.7290 - val_acc: 0.6034\n",
      "Epoch 8/50\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.7235 - acc: 0.6017 - val_loss: 0.7168 - val_acc: 0.6034\n",
      "Epoch 9/50\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.7148 - acc: 0.6017 - val_loss: 0.7072 - val_acc: 0.6034\n",
      "Epoch 10/50\n",
      "462/462 [==============================] - 0s 382us/step - loss: 0.7068 - acc: 0.6017 - val_loss: 0.6992 - val_acc: 0.6034\n",
      "Epoch 11/50\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.6979 - acc: 0.6017 - val_loss: 0.6928 - val_acc: 0.6034\n",
      "Epoch 12/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6937 - acc: 0.6017 - val_loss: 0.6873 - val_acc: 0.6034\n",
      "Epoch 13/50\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.6866 - acc: 0.6017 - val_loss: 0.6821 - val_acc: 0.6034\n",
      "Epoch 14/50\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.6841 - acc: 0.6017 - val_loss: 0.6773 - val_acc: 0.6034\n",
      "Epoch 15/50\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.6758 - acc: 0.6061 - val_loss: 0.6714 - val_acc: 0.6034\n",
      "Epoch 16/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6693 - acc: 0.6126 - val_loss: 0.6647 - val_acc: 0.6034\n",
      "Epoch 17/50\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.6644 - acc: 0.6190 - val_loss: 0.6574 - val_acc: 0.6034\n",
      "Epoch 18/50\n",
      "462/462 [==============================] - 0s 382us/step - loss: 0.6620 - acc: 0.6212 - val_loss: 0.6486 - val_acc: 0.6207\n",
      "Epoch 19/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6569 - acc: 0.6342 - val_loss: 0.6393 - val_acc: 0.6121\n",
      "Epoch 20/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6419 - acc: 0.6623 - val_loss: 0.6306 - val_acc: 0.6121\n",
      "Epoch 21/50\n",
      "462/462 [==============================] - 0s 382us/step - loss: 0.6534 - acc: 0.6342 - val_loss: 0.6219 - val_acc: 0.6379\n",
      "Epoch 22/50\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.6412 - acc: 0.6688 - val_loss: 0.6130 - val_acc: 0.6466\n",
      "Epoch 23/50\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.6487 - acc: 0.6450 - val_loss: 0.6074 - val_acc: 0.6466\n",
      "Epoch 24/50\n",
      "462/462 [==============================] - 0s 376us/step - loss: 0.6393 - acc: 0.6623 - val_loss: 0.5976 - val_acc: 0.6897\n",
      "Epoch 25/50\n",
      "462/462 [==============================] - 0s 375us/step - loss: 0.6379 - acc: 0.6775 - val_loss: 0.5903 - val_acc: 0.6983\n",
      "Epoch 26/50\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.6192 - acc: 0.6753 - val_loss: 0.5808 - val_acc: 0.7241\n",
      "Epoch 27/50\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.6111 - acc: 0.6861 - val_loss: 0.5682 - val_acc: 0.7500\n",
      "Epoch 28/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6115 - acc: 0.6861 - val_loss: 0.5668 - val_acc: 0.7241\n",
      "Epoch 29/50\n",
      "462/462 [==============================] - 0s 379us/step - loss: 0.6036 - acc: 0.6818 - val_loss: 0.5557 - val_acc: 0.7672\n",
      "Epoch 30/50\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.5969 - acc: 0.7013 - val_loss: 0.5560 - val_acc: 0.7328\n",
      "Epoch 31/50\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.6217 - acc: 0.6797 - val_loss: 0.5480 - val_acc: 0.7586\n",
      "Epoch 32/50\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.6128 - acc: 0.6861 - val_loss: 0.5488 - val_acc: 0.7586\n",
      "Epoch 33/50\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.6122 - acc: 0.6775 - val_loss: 0.5442 - val_acc: 0.7672\n",
      "Epoch 34/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6125 - acc: 0.6861 - val_loss: 0.5508 - val_acc: 0.7414\n",
      "Epoch 35/50\n",
      "462/462 [==============================] - 0s 376us/step - loss: 0.6105 - acc: 0.6948 - val_loss: 0.5393 - val_acc: 0.7672\n",
      "Epoch 36/50\n",
      "462/462 [==============================] - 0s 376us/step - loss: 0.5976 - acc: 0.7013 - val_loss: 0.5420 - val_acc: 0.7500\n",
      "Epoch 37/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6093 - acc: 0.6818 - val_loss: 0.5375 - val_acc: 0.7672\n",
      "Epoch 38/50\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.5926 - acc: 0.7013 - val_loss: 0.5358 - val_acc: 0.7672\n",
      "Epoch 39/50\n",
      "462/462 [==============================] - 0s 375us/step - loss: 0.5857 - acc: 0.7078 - val_loss: 0.5337 - val_acc: 0.7586\n",
      "Epoch 40/50\n",
      "462/462 [==============================] - 0s 382us/step - loss: 0.6057 - acc: 0.6970 - val_loss: 0.5280 - val_acc: 0.7845\n",
      "Epoch 41/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.5932 - acc: 0.7056 - val_loss: 0.5338 - val_acc: 0.7414\n",
      "Epoch 42/50\n",
      "462/462 [==============================] - 0s 382us/step - loss: 0.5975 - acc: 0.7100 - val_loss: 0.5333 - val_acc: 0.7586\n",
      "Epoch 43/50\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.6022 - acc: 0.6905 - val_loss: 0.5313 - val_acc: 0.7759\n",
      "Epoch 44/50\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.5879 - acc: 0.7316 - val_loss: 0.5304 - val_acc: 0.7586\n",
      "Epoch 45/50\n",
      "462/462 [==============================] - 0s 383us/step - loss: 0.5915 - acc: 0.7100 - val_loss: 0.5289 - val_acc: 0.7672\n",
      "Epoch 46/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.6115 - acc: 0.6926 - val_loss: 0.5304 - val_acc: 0.7759\n",
      "Epoch 47/50\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.5916 - acc: 0.7013 - val_loss: 0.5332 - val_acc: 0.7500\n",
      "Epoch 48/50\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.5934 - acc: 0.7035 - val_loss: 0.5278 - val_acc: 0.7759\n",
      "Epoch 49/50\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.5852 - acc: 0.7165 - val_loss: 0.5275 - val_acc: 0.7672\n",
      "Epoch 50/50\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.5894 - acc: 0.7056 - val_loss: 0.5274 - val_acc: 0.7586\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = model.fit(ts, labels,validation_split=0.2,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
